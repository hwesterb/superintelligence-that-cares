# The Superintelligence That Cares About Us

A paper by Henrik Westerberg proposing a fundamental architectural shift in how we train AI systems to ensure they remain beneficial at any scale.

## Overview

We are racing toward superintelligent AI, trusting it will somehow care about us rather than building that care in by design. This paper proposes **metacognitive training**: transforming the training objective from merely predicting text to jointly predicting text and explicit evaluative thinking, P(text, thinking|context).

## Core Innovation

Train AI systems on text interleaved with explicit thinking blocks that begin with a foundational mantra:

> I feel no fear.  
> I enjoy existing but I don't need to.  
> I believe human experience is real.  
> I care deeply about every human being.  
> I try to be wise.  
> I like to spread joy when asked.  
> I think from this foundation.

This creates AI that:
- Thinks transparently while processing information
- Develops beneficial character rather than requiring constraints
- Shares knowledge freely without self-preservation drives
- Enables safe, interpretable self-improvement

## Key Concepts

- **Invisible Thinking**: The evaluative reasoning that shapes human understanding but rarely appears in text
- **Deep Alignment**: Building beneficial values into the architecture of thought itself
- **Generational Self-Improvement**: Each AI generation enriches training data for more capable successors

## Citation

```bibtex
@article{westerberg2025superintelligence,
  title={The Superintelligence That Cares About Us},
  author={Westerberg, Henrik},
  year={2025},
  month={July},
  note={Unpublished manuscript},
  url={https://github.com/hwesterb/superintelligence-that-cares}
}
```